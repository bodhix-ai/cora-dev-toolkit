# Context: Evaluation Optimization Initiative

**Created:** February 4, 2026  
**Primary Focus:** Business Analyst Workbench for prompt optimization in module-eval

## Initiative Overview

The Evaluation Optimization initiative develops a **supplemental application** (companion to the main CORA app) that enables business analysts to optimize prompt configurations for document evaluation processing. The system uses sample-driven training with human-verified "truth keys" to tune prompts for specific document domains (IT security policies, appraisals, proposals, etc.), reducing false positives and false negatives in automated evaluations.

### ğŸš¨ CRITICAL: RAG Architecture Constraint

**Module-kb is the ONLY RAG provider. DO NOT build new RAG infrastructure.**

| Component | Provider | NOT This âŒ |
|-----------|----------|-------------|
| Document Storage | **module-kb** (existing) | âŒ New storage service |
| Embeddings | **module-ai** (existing) | âŒ Direct OpenAI/Titan calls |
| Vector Search | **module-kb** (existing) | âŒ Pinecone, Weaviate, pgvector |
| Context Docs | **Workspace KB** (existing) | âŒ Separate eval_opt_context_docs storage |

**Implementation:**
1. Context documents are KB documents in the workspace
2. Use existing module-kb APIs for upload, storage, and RAG
3. Embeddings handled by module-ai (already integrated with module-kb)
4. **Zero new vector infrastructure required**

### Target Users
- **Business Analysts** optimizing evaluation configurations for document domains
- **Not** end users performing document evaluations (different workflow, different UI needs)

### Core Problem
Currently, module-eval uses the same prompt for all document types, leading to suboptimal accuracy across different domains. This initiative creates a systematic approach to optimize prompts per domain using:
- Sample documents with human-verified evaluation results (truth keys)
- Statistical confidence metrics on optimization quality
- Guidance on sample size requirements for production readiness

## Sprint History

| Sprint | Branch | Plan | Status | Completed |
|--------|--------|------|-----------|--------------
| S1 | `feature/eval-optimization-s1` | `plan_eval-optimization-s1.md` | âœ… COMPLETE | All phases (Arch, Prototype, ConOps, ADR-021) |
| S2 | `feature/eval-optimization-s2` | `plan_eval-optimization-s2.md` | ğŸš§ IN PROGRESS | Phase 0 âœ…, Phase 1 âœ… |

## Current Sprint

- **Sprint 1:** âœ… COMPLETE (Feb 5, 2026 AM)
- **Sprint 2:** âœ… COMPLETE (Feb 5, 2026)
- **Branch:** `feature/eval-optimization-s2`
- **Plan:** `docs/plans/plan_eval-optimization-s2.md`
- **Status:** All code merged to main - Ready for Sprint 3
- **Current Phase:** Sprint 2 COMPLETE
- **Duration:** 2.5 weeks
- **Progress:** 100% complete (Phase 4D/5 deferred to Sprint 3)
- **Next Session:** Sprint 3 - Integration testing + results display

## Key Design Decisions

### 1. Deployment Architecture (DECIDED - ADR-021)

**Status:** âœ… Complete - ADR-021 documents decision

**Decision:** Option A (Same Stack Repo at `{project}-stack/apps/eval-optimizer/`)

**Rationale:**
- âœ… Zero code duplication (imports from workspace packages)
- âœ… Shared authentication (same Cognito/NextAuth)
- âœ… Zero additional infrastructure cost
- âœ… Independent build/deploy pipeline (port 3001)
- âœ… Familiar monorepo patterns
- âœ… **Enables paid feature monetization** (Sprint 2 insight)

**Trade-offs:**
- âš ï¸ Deployment coupling (mitigated by independent pipelines)
- âœ… Overall: Benefits outweigh costs

**Alternatives Rejected:**
- **Option B (Separate Repo):** High duplication cost, maintenance overhead
- **Option C (Toolkit Utility):** Not production-ready, wrong abstraction
- **Option D (Module-Eval Admin):** Prevents monetization as paid feature

**Strategic Rationale:**
- Open Source Core: module-eval (evaluation execution) - FREE
- Paid Enhancement: eval-optimizer (BA Workbench) - PAID ADD-ON
- Business Model: Sustainable funding while keeping CORA core open source

**Documentation:** See `docs/arch decisions/ADR-021-EVAL-OPTIMIZER-DEPLOYMENT.md`

### 2. Truth Key Versioning (DECIDED - Sprint 2)

**Status:** âœ… Complete - Sprint 2 planning

**Decision:** Version truth keys against specific doc_type + criteria_set combination

**Rationale:**
- Truth keys are only valid for specific doc_type + criteria_set
- If criteria change, old truth keys may not apply
- Need to track validity and invalidate when criteria updated

**Implementation:**
- `doc_type_id` captured at evaluation time
- `criteria_set_version` tracked
- `is_valid` flag to mark outdated truth keys
- `invalidation_reason` for audit trail

### 3. System-Level Configuration (DECIDED - Sprint 2) ğŸ¯ **CRITICAL**

**Status:** âœ… Complete - Sprint 2 planning

**Decision:** Promote doc type + criteria set to system-level shared configurations

**Rationale:**
- **Efficiency:** BAs create truth sets once (not per-org)
- **Faster Onboarding:** Orgs inherit pre-configured, pre-optimized settings
- **Quality:** Centralized optimization benefits entire platform
- **Visibility:** Dashboard shows which combinations need work

**Implementation:**
- New tables: `eval_sys_doc_types`, `eval_sys_criteria_sets`, `eval_sys_criteria_items`
- Org adoption: `eval_org_adopted_configs` (inheritance model)
- Projects reference system-level configs (not org-level)
- BA Task Management Dashboard shows coverage gaps

**Benefits:**
- âœ… No duplicate manual evaluation work across orgs
- âœ… IT Security Policies + NIST optimized once, all orgs benefit
- âœ… New orgs: "Enable IT Security Policies (NIST)" â†’ Done
- âœ… Consistent evaluation standards across platform

**Trade-offs:**
- âš ï¸ Requires system admin privileges to create doc types
- âš ï¸ Reduced org flexibility (but can customize if needed)
- âœ… Net Positive: Major efficiency gain outweighs trade-offs

### 2. Application Architecture (DECIDED)

**Type:** Standalone companion application (NOT admin feature in main app)

**Rationale:**
- Different user persona (analysts vs. end users)
- Different workflows (prompt tuning vs. document evaluation)
- UI optimized for iterative optimization cycles
- Can evolve independently without cluttering main app

**Authentication:** Uses same Cognito/NextAuth as main CORA app
- Single identity across both apps
- Leverage existing auth infrastructure

### 3. API Integration Scope (DECIDED)

The optimizer app calls APIs from **4 CORA modules**:

| Module | Purpose | Example Operations |
|--------|---------|-------------------|
| **module-access** | Org context management | Create test orgs for optimization runs |
| **module-ws** | Workspace container | Create workspaces for test documents |
| **module-kb** | Document management | Upload sample docs to knowledge base |
| **module-eval** | Evaluation execution | Run evaluations with different prompt configs |

**Org Management Strategy:** Create dedicated test orgs with naming convention `eval-opt-{domain}-{timestamp}` to:
- Isolate optimization data from production
- Allow cleanup after optimization runs
- Track experiments separately

## Core Workflow

```
1. Create Test Org (module-access)
      â†“
2. Create Workspace (module-ws)
      â†“
3. Upload Sample Document (module-kb)
      â†“
4. Define Truth Key (expected evaluation results)
      â†“
5. Configure Eval Prompt (prompt management - new feature)
      â†“
6. Run Evaluation (module-eval)
      â†“
7. Compare Results vs Truth Key (optimization logic - new feature)
      â†“
8. Analyze Confidence Metrics (sample coverage analysis - new feature)
      â†“
9. Iterate: Adjust prompt â†’ Repeat steps 5-8
      â†“
10. Deploy Optimized Prompt (per domain configuration - new feature)
```

## Sample-Driven Optimization Concept

### Input Format
- **Sample Documents:** Real documents from target domain
- **Truth Keys:** Human analyst's evaluation results (the "correct" answers)
  - Compliance scores per criterion
  - Expected findings
  - Identified risks/issues

### Confidence & Sample Size Guidance

The system provides statistical guidance on result reliability based on sample size:

| Sample Size | Confidence Level | User Guidance |
|-------------|-----------------|---------------|
| 1 example | âš ï¸ Very Low | "Single example cannot establish pattern. Results may not generalize." |
| 2-5 examples | ğŸŸ¡ Low | "Limited samples. Add more diverse examples for reliable patterns." |
| 6-15 examples | ğŸŸ¢ Moderate | "Reasonable coverage. Consider edge cases and variations." |
| 16+ examples | âœ… High | "Strong sample set. Prompt should generalize well to new documents." |

### Truth Key Format (DECIDED)

**Format:** Excel/CSV spreadsheet with two sheets
- **Sheet 1:** Document-level truth keys (overall compliance, key findings)
- **Sheet 2:** Criteria-level truth keys (per-criterion status, confidence, notes)

**Documentation:** See ConOps Section 4 for complete specification

## Key Features (Defined in ConOps)

### 1. Sample Coverage Analysis
- Track document variations in training set
- Identify gaps (e.g., "no examples with tables", "no multi-page docs")
- Suggest additional example types needed for robust optimization

### 2. Optimization Metrics Dashboard
- Accuracy vs truth keys (per criterion)
- False positive / false negative rates
- Precision and recall metrics
- Confidence intervals based on sample size
- Trend analysis across prompt iterations

### 3. Prompt Versioning & Comparison
- Track prompt iterations with metadata (author, date, description)
- A/B compare different prompt versions
- Show which version performs best on test set
- Rollback capability to previous versions

### 4. Domain Configuration Management
- Manage prompts per document domain:
  - IT Security Policies â†’ Prompt A (optimized)
  - Appraisals â†’ Prompt B (optimized)
  - Proposals â†’ Prompt C (optimized)
  - FOIA Requests â†’ Prompt D (optimized)
- Domain-specific evaluation criteria
- Import/export domain configurations

### 5. Batch Testing & Validation
- Run optimized prompt against entire sample set
- Cross-validation across sample partitions
- Performance degradation detection
- Regression testing when prompt changes

## Technical Architecture

### Frontend
- Next.js application (consistent with CORA stack pattern)
- TypeScript + React
- Shared UI library components from main app (workspace packages)
- Analyst-focused UX: iterative workflows, data visualization

### Backend
- API Gateway â†’ Lambda (consistent with CORA pattern)
- Leverages existing CORA module APIs
- New optimizer-specific APIs for:
  - Truth key management
  - Prompt versioning
  - Optimization metrics calculation
  - Sample coverage analysis

### Data Storage
- Supabase/PostgreSQL (consistent with CORA)
- New tables (namespaced `eval_opt_*`):
  - `eval_optimization_projects`
  - `eval_opt_project_members`
  - `eval_opt_document_groups`
  - `eval_opt_truth_keys`
  - `eval_prompt_versions`
  - `eval_opt_runs`
  - `eval_opt_run_results`

**Database Schema:** See ConOps Section 10 for complete schema

## Success Criteria

### Sprint 1 (Architecture Analysis) âœ… COMPLETE
- [x] âœ… ADR-021 created documenting deployment architecture decision
- [x] âœ… Minimal prototype proves:
  - [x] Auth works (same Cognito/NextAuth as main app)
  - [x] Can call module-access, ws, kb, eval APIs
  - [x] Can create org, workspace, upload doc, run eval
- [x] âœ… Recommendation documented with pros/cons of each option
- [x] âœ… ConOps document for optimization methodology
- [x] âœ… Sprint 2 implementation plan

### Overall Initiative (Multi-Sprint)
- [ ] Business analysts can upload sample docs with truth keys
- [ ] System optimizes prompts per document domain
- [ ] Confidence metrics guide analysts on sample size needs
- [ ] Optimized prompts improve eval accuracy (measurable reduction in false positives/negatives)
- [ ] Domain-specific prompt configurations deployed to production module-eval

## Key Decisions & ADRs

- **ADR-021 (Accepted):** Eval Optimizer Deployment Architecture
  - Documents deployment decision: Option A (Same Stack Repo)
  - Created: February 5, 2026
  - Location: `docs/arch decisions/ADR-021-EVAL-OPTIMIZER-DEPLOYMENT.md`

## Session Log

### February 5, 2026 Morning (10:00 AM) - Sprint 2 Phase 2 & 3 Complete

**Session Duration:** 1 hour 12 minutes  
**Branch:** `feature/eval-optimization-s2`  
**Objective:** Implement sample document management and manual evaluation UI

**Phase 2 Completed:**

1. **Sample Document Management**
   - âœ… Updated `app/projects/[id]/page.tsx` - Added Samples tab
   - âœ… Created `components/DocumentGroupCard.tsx` (200+ lines)
   - âœ… Created `components/DocumentUploader.tsx` (150+ lines)
   - âœ… Created `app/projects/[id]/samples/upload/page.tsx` (300+ lines)
   - âœ… Updated API README with sample management routes

2. **API Documentation Extended**
   - âœ… `GET /api/projects/{id}/samples` - List samples
   - âœ… `POST /api/projects/{id}/samples/upload` - Upload with module-kb integration
   - âœ… `GET /api/projects/{id}/samples/{group_id}` - Get document group
   - âœ… `DELETE /api/projects/{id}/samples/{group_id}` - Delete sample

**Phase 3 Completed:**

1. **Manual Evaluation UI - Truth Key Creation**
   - âœ… Created `components/DocumentViewer.tsx` (122 lines)
     - Document content display with text selection
     - Real-time selected text feedback
     - Citation-ready UX
   
   - âœ… Created `components/CriteriaEvaluationForm.tsx` (260 lines)
     - Status dropdown (Compliant, Non-compliant, etc.)
     - Confidence slider (0-100%)
     - Explanation textarea
     - Citations list with add/remove
     - Visual completion indicator
   
   - âœ… Created `app/projects/[id]/evaluate/[group_id]/page.tsx` (403 lines)
     - Split-screen layout (document left, criteria right)
     - Progress tracking (e.g., "7 of 10 criteria evaluated - 70%")
     - Real-time text selection â†’ citation flow
     - Batch save (all criteria in one transaction)
     - Form validation (must complete all criteria)

2. **API Documentation Extended**
   - âœ… `GET /api/projects/{id}/samples/{group_id}/evaluate` - Load doc + criteria
   - âœ… `POST /api/projects/{id}/truth-keys` - Save evaluations (batch UPSERT)
   - âœ… `GET /api/projects/{id}/truth-keys` - List truth keys
   - âœ… `PUT /api/projects/{id}/truth-keys/{id}` - Update single truth key
   - âœ… `DELETE /api/projects/{id}/truth-keys/{id}` - Delete truth key

**Key Innovation:**
- Truth keys created via web UI (not Excel upload)
- Analysts read document while evaluating criteria in parallel
- Text selection â†’ citation flow is seamless
- Progress bar shows completion (visual feedback)
- Batch save ensures atomic truth key creation

**Phase 2 & 3 Complete:**
- âœ… All frontend UI components created (7 new files)
- âœ… API routes documented (backend implementation pending)
- âœ… Follows CORA patterns (ADR-004: NextAuth API Client Pattern)
- âœ… Split-screen evaluation UX (critical user experience)

**Next Session:**
- Phase 4: Optimization run backend logic
- Start with: Orchestrator to call module-eval and compare results to truth keys

---

### February 5, 2026 Morning (9:33 AM) - Sprint 2 Phase 1 Complete

**Session Duration:** 1 hour 12 minutes  
**Branch:** `feature/eval-optimization-s2`  
**Objective:** Create project management UI for the BA Workbench

**Completed:**

1. **Project List Page**
   - âœ… Created `app/projects/page.tsx` (276 lines)
   - âœ… Displays all optimization projects user has access to
   - âœ… Project cards with metadata (name, domain, samples, accuracy)
   - âœ… Create new project button
   - âœ… Role-based display (owner/admin/user badges)
   - âœ… Empty state with call-to-action

2. **Project Creation Form**
   - âœ… Created `app/projects/new/page.tsx` (408 lines)
   - âœ… Form with project name, description, domain fields
   - âœ… Doc type selector (loads from module-eval API)
   - âœ… Criteria set selector (loads from module-eval API)
   - âœ… Form validation and error handling
   - âœ… Info box about doc type + criteria set immutability

3. **Project Detail Page**
   - âœ… Created `app/projects/[id]/page.tsx` (770 lines)
   - âœ… Project header with stats summary (samples, evaluations, accuracy)
   - âœ… Tab navigation (Overview, Samples, Evaluations, Runs, Members)
   - âœ… Overview tab with configuration and activity cards
   - âœ… Members tab with full member management UI:
     - Add member form (email + role selection)
     - Member list with role badges
     - Remove member functionality (owner/admin only)
     - Permission checks (can't remove last owner)
   - âœ… Placeholder tabs for future phases (Samples, Evaluations, Runs)

4. **API Routes Documentation**
   - âœ… Created `app/api/README.md` (comprehensive spec)
   - âœ… Documented all project CRUD endpoints
   - âœ… Documented member management endpoints
   - âœ… Included database queries and authorization rules
   - âœ… Specified request/response formats

5. **Reusable Components**
   - âœ… ProjectCard component (embedded in project list)
   - âœ… ProjectMembers component (MembersTab in project detail)
   - âœ… Helper functions (getRoleColor, formatDate)

**Phase 1 Complete:**
- âœ… All frontend UI pages created
- âœ… API routes documented (backend implementation pending)
- âœ… Follows CORA patterns (ADR-004: NextAuth API Client Pattern)
- âœ… Consistent with Sprint 1 prototype patterns

**Next Session:**
- Phase 2: Sample document management (upload, list, delete)
- Start with: `app/projects/[id]/samples/page.tsx`

---

### February 5, 2026 Morning (9:21 AM) - Sprint 2 Phase 0 Complete

**Session Duration:** 2 hours 9 minutes  
**Branch:** `feature/eval-optimization-s2`  
**Objective:** Create module-eval-optimizer structure with idempotent database schemas

**Completed:**

1. **Module Structure Created**
   - âœ… Created complete module directory structure
   - âœ… Created module.config.yaml, module.json, README.md
   - âœ… Created infrastructure Terraform stubs (main.tf, variables.tf, outputs.tf, versions.tf)
   - âœ… Created frontend stub (index.ts)

2. **Database Schemas Created (6 files)**
   - âœ… 001-eval-opt-projects.sql (projects, members, test orgs)
   - âœ… 002-eval-opt-doc-groups.sql (doc groups, group members)
   - âœ… 003-eval-opt-truth-keys.sql (truth keys)
   - âœ… 004-eval-opt-runs.sql (optimization runs, run results)
   - âœ… 005-eval-opt-prompt-versions.sql (prompt versions, deployments)
   - âœ… 006-eval-opt-rls.sql (all RLS policies)

3. **Idempotency Fixes Applied**
   - âœ… Fixed RLS column references (person_id â†’ user_id, removed 'active')
   - âœ… Restructured files to follow pattern (tables â†’ RLS in final file)
   - âœ… Made all constraint additions idempotent (DO blocks with pg_constraint check)
   - âœ… Made all RLS policies idempotent (DROP POLICY IF EXISTS before CREATE)
   - âœ… All 6 files tested and confirmed idempotent

4. **Schema Pattern Compliance**
   - âœ… Tables in separate files (001-005)
   - âœ… RLS policies in final file (006)
   - âœ… All operations can be run multiple times without errors

**Database Schema:**
- 10 tables created with complete RLS policies
- All tables follow naming conventions (eval_opt_* prefix)
- Hybrid abbreviation pattern (readable table names, abbreviated foreign keys)

---

### February 5, 2026 Morning (7:12-7:55 AM) - Sprint 2 Planning Complete

**Session Duration:** 43 minutes  
**Branch:** `feature/eval-optimization-s2`  
**Objective:** Define Sprint 2 plan and establish architectural foundations

**Completed:**

1. **Documentation Cleanup**
   - âœ… Updated `plan_eval-optimization.md` - Marked 406/RLS errors as RESOLVED
   - âœ… Updated status: "Evaluation Accuracy Optimization" (not troubleshooting)
   - âœ… Clarified current focus: Pipeline works, results need optimization

2. **Sprint 2 Plan Created**
   - âœ… Created `docs/plans/plan_eval-optimization-s2.md`
   - âœ… Comprehensive 5-phase implementation plan (2-3 weeks)
   - âœ… Database schema designed for all tables
   - âœ… Frontend/backend components specified
   - âœ… Success criteria defined

3. **Critical Architectural Decisions**

   **Decision 1: Truth Key Versioning**
   - âœ… Truth keys must be versioned against specific doc_type + criteria_set
   - âœ… Added `doc_type_id`, `criteria_set_version`, `is_valid` fields
   - âœ… Enables invalidation when criteria change

   **Decision 2: System-Level Configuration** ğŸ¯ **CRITICAL**
   - âœ… Promoted doc types and criteria sets to system-level
   - âœ… Created `eval_sys_doc_types`, `eval_sys_criteria_sets` tables
   - âœ… Orgs inherit pre-configured combinations via `eval_org_adopted_configs`
   - âœ… BAs create truth sets once (not per-org) - Major efficiency gain
   - âœ… Added BA Task Management Dashboard specification

   **Decision 3: Strategic Business Rationale** ğŸ’°
   - âœ… Confirmed separate app architecture enables paid feature monetization
   - âœ… Open Source Core: module-eval (evaluation execution) - FREE
   - âœ… Paid Enhancement: eval-optimizer (BA Workbench) - PAID ADD-ON
   - âœ… Mirrors successful models: GitLab, Elastic, MongoDB

4. **ADR-021 Updated**
   - âœ… Added Sprint 2 Addendum: System-level configuration architecture
   - âœ… Added Alternative 4: Module-eval admin feature (rejected for monetization)
   - âœ… Added Strategic Business Rationale section
   - âœ… Documented open source + paid add-on model

**Key Innovation:**
- Truth keys created via web UI (not Excel upload)
- Analyst evaluates document in browser â†’ Creates truth key records
- As more docs manually evaluated, AI optimization improves over time

**Sprint 2 Ready:**
- âœ… Comprehensive plan document created
- âœ… Database schema designed (system-level and optimizer tables)
- âœ… Frontend components specified (5 phases)
- âœ… Success criteria defined
- âœ… Architecture decisions documented
- âœ… Next session can start implementation (Phase 1: Database migrations)

**Next Steps:**
1. Create database migrations for Sprint 2 tables
2. Implement Phase 1: Project management UI
3. Implement Phase 2: Sample document upload
4. Implement Phase 3: Manual evaluation UI (truth key creation)
5. Implement Phase 4: Optimization run backend
6. Implement Phase 5: Results display and A/B comparison

---

### February 5, 2026 Morning (Earlier) - Sprint 1 Complete

**Session Duration:** 30 minutes  
**Branch:** `feature/eval-optimization-s1`

**Completed:**
- âœ… **Phase 3: Option Evaluation**
  - Analyzed deployment options A/B/C
  - Filled decision matrix with prototype findings
  - Confirmed Option A (Same Stack Repo) as best choice
  
- âœ… **Phase 4: Decision & Documentation**
  - Created ADR-021: Eval Optimizer Deployment Architecture
  - Documented architecture decision with clear rationale
  - Updated Sprint 1 plan to mark all phases complete
  - Created Sprint 2 implementation roadmap

**Architecture Decision:**
- **Selected:** Option A (Same Stack Repo at `apps/eval-optimizer/`)
- **Rationale:** Zero code duplication, shared authentication, minimal infrastructure
- **Evidence:** Prototype validated all key integration points
- **Documentation:** ADR-021 provides comprehensive analysis

**Sprint 1 Outcomes:**
- All deliverables complete (architecture research, prototype, ConOps, ADR-021)
- Clear path forward for Sprint 2 implementation
- Technical decisions resolved (auth, API client, database, deployment)
- Risk mitigation strategies identified

### February 4, 2026 Evening - ConOps Development Complete
**Session Duration:** 1.5 hours  
**Branch:** `feature/eval-optimization-s1`

**Completed:**
- âœ… **Concept of Operations Document Created**
  - Created `docs/specifications/spec_eval-optimization-conops.md`
  - Comprehensive 13-section document (15,000+ words)
  - Captured all requirements from user discussions
  
**ConOps Document Includes:**
1. **Executive Summary** - Value proposition and target users
2. **Core Concepts** - Document domains, truth keys, optimization runs, document groups
3. **Sample-Driven Optimization Theory** - Statistical foundation, iteration model, multi-model support
4. **Analyst Workflow** - 6-phase workflow from project setup to production deployment
5. **Truth Key Specification** - Spreadsheet format, validation rules, import process
6. **Prompt Version Management** - Database-driven versioning, A/B comparison, rollback
7. **Quality Metrics** - Accuracy, precision/recall, F1, error analysis, confidence calibration
8. **Scalability Design** - Scale tiers (1-1000+ samples), processing architecture, cost estimation
9. **Access Control Model** - Owner/Admin/User roles aligned with CORA standards
10. **Production Deployment** - Workflow, deployment options, validation, monitoring
11. **Database Schema** - Complete schema for all optimization tables
12. **Success Criteria** - System-level, business outcomes, technical performance
13. **Implementation Roadmap** - Sprint 2-5 breakdown

**Key Requirements Captured:**
- âœ… Spreadsheet-based truth key upload (user requirement)
- âœ… Document group support (policy + proof artifacts)
- âœ… Multi-model optimization (GPT-4, Claude, Nova, etc.)
- âœ… Configuration parameter optimization (temperature, max_tokens, etc.)
- âœ… Version management for prompts (deployment workflow)
- âœ… Owner/Admin/User access control (CORA standard)
- âœ… Sample size guidance (1 to 1000s of truth keys)
- âœ… Statistical confidence metrics

### February 4, 2026 PM - Phase 1 & 2 Complete
**Session Duration:** 3 hours  
**Branch:** `feature/eval-optimization-s1`

**Completed:**
- âœ… **Phase 1: Architecture Research**
  - Reviewed ADR-004 (NextAuth API Client Pattern), ADR-007 (CORA Auth Shell), ADR-019 (Auth Standardization)
  - Analyzed module-eval prompt configuration flow (database â†’ resolution â†’ AI provider)
  - Documented code reuse opportunities (auth, API client, types)
  - Identified infrastructure requirements per deployment option
  
- âœ… **Phase 2: Prototype Development**
  - Created Option A prototype in `templates/_project-stack-template/apps/eval-optimizer/`
  - Built 10 files (887 lines): package.json, auth.ts, middleware.ts, app pages, API client
  - Proved shared authentication (same Okta/Cognito config)
  - Proved code reuse (imports from workspace packages)
  - Proved API integration (factory pattern, ADR-004 compliance)
  - Documented prototype in comprehensive README.md

**Findings:**
- Option A (Same Stack Repo) is viable and demonstrates strong advantages:
  - âœ… Zero code duplication
  - âœ… Shared authentication (single Cognito user pool)
  - âœ… Direct imports from workspace packages
  - âœ… Zero additional infrastructure
  - âœ… Independent build/deploy pipeline

### February 4, 2026 AM - Initiative Creation
- Defined initiative scope: standalone companion app for prompt optimization
- Identified need for architecture analysis in Sprint 1 before committing to deployment model
- Clarified API scope: module-access, ws, kb, eval
- Established sample-driven optimization concept with confidence metrics
- Documented truth key approach and statistical guidance requirements

## Related Initiatives

- **Module-Eval Development** (`context-module-eval.md`) - P2/P3 priority
  - This initiative complements eval development by providing optimization tooling
  - Not blocked by citations/scoring work - can prototype against existing APIs

## Priority & Work Lane

- **Priority:** P2-P3 (supports eval delivery but independent)
- **Lane:** H (AI Platform) - prompt engineering infrastructure
- **Dependencies:** None (can prototype against existing CORA APIs)
- **Conflict Risk:** Low (mostly new files, minimal overlap with other work)

## Sprint 1 Summary

**Status:** âœ… COMPLETE (February 5, 2026)

**All Deliverables Complete:**
- âœ… Phase 1: Architecture Research
- âœ… Phase 2: Prototype Development (Option A validated)
- âœ… ConOps: Comprehensive specification (13 sections)
- âœ… Phase 3: Option Evaluation (A/B/C comparison)
- âœ… Phase 4: ADR-021 + Sprint 2 roadmap

**Architecture Decision:** Option A (Same Stack Repo)

**Next:** Sprint 2 implementation pending team capacity and prioritization

---

## Sprint 2 Progress Tracker

| Phase | Status | Deliverables | Completion |
|-------|--------|--------------|------------|
| Phase 0 | âœ… COMPLETE | Module structure, database schemas (7 tables), RLS policies | 100% |
| Phase 1 | âœ… COMPLETE | Workspace management UI (refactored from projects) | 100% |
| Phase 2 | âœ… COMPLETE | Sample document management (upload, list, delete) | 100% |
| Phase 3 | âœ… COMPLETE | Manual evaluation UI (truth key creation) | 100% |
| Phase 4A | âœ… COMPLETE | Route refactoring + Context tab UI | 100% |
| Phase 4A+ | âœ… COMPLETE | All remaining UI pages + ResponseStructureBuilder | 100% |
| Phase 4B | âœ… COMPLETE | Backend Lambda + supporting modules | 100% |
| Phase 4C | âœ… COMPLETE | Terraform infrastructure + Lambda layer | 100% |
| Phase 4D | ğŸ“‹ NEXT | Integration testing | 0% |
| Phase 5 | ğŸ“‹ PLANNED | Results display & A/B comparison | 0% |

**Overall Sprint 2 Progress:** âœ… COMPLETE - Merged to main (Phase 4D/5 deferred to Sprint 3)

---

## Phase 4 Redesign Discovery (CRITICAL)

**Date:** February 5, 2026 PM  
**Status:** ğŸ”„ MAJOR PIVOT - Original Phase 4 implementation is fundamentally wrong

### The Fundamental Misunderstanding

**What was initially implemented (WRONG):**
- BA manually writes prompts using PromptConfigForm
- BA manually configures temperature, max_tokens
- BA manually runs optimization with their prompts
- BA manually iterates on prompt configurations

**Correct product vision (discovered through user feedback):**
- BA creates truth keys (manual evaluation of sample documents) âœ… Correct
- BA uploads domain context documents (NEW)
- BA defines desired response structure (NEW)
- **SYSTEM automatically generates and tests prompts** (THE SECRET SAUCE)
- SYSTEM finds best configuration automatically
- SYSTEM provides recommendations for improvement

### Why Domain-Aware Prompt Generation is Critical

Generic prompts ("be strict", "be lenient") don't work for specialized domains:

- **CJIS IT Security Audits:** Must reference security controls, CJIS standards, evidence requirements
- **Federal Appraisals:** Must reference valuation methods, comparables, market analysis  
- **FOIA Requests:** Must reference exemptions, redaction rules, public interest

The system must understand the domain context and generate contextually appropriate prompts.

### The New Approach: RAG + LLM Meta-Prompting

**Workflow:**
```
1. BA uploads context documents (CJIS requirements, appraisal guides, etc.)
   â†“
2. System performs RAG on context docs
   - Extract key concepts, standards, terminology
   - Build domain knowledge base
   â†“
3. BA defines response structure (JSON builder UI)
   - score_justification
   - compliance_gaps
   - recommendations
   â†“
4. BA clicks "Start Optimization"
   â†“
5. System generates 5-7 domain-aware prompts via LLM
   - Uses RAG knowledge
   - References domain standards
   - Produces structured JSON
   - Variations: evidence-focused, standard-focused, risk-focused, etc.
   â†“
6. System tests all variations automatically
   - Runs module-eval for each prompt
   - Compares AI results to truth keys
   - Calculates accuracy metrics
   â†“
7. System shows best configuration + recommendations
   - "Add 7 more truth sets for +10% accuracy"
   - "Run refinement optimization"
   - "High false positives - try stricter prompts"
```

### What Needs to Be Built

**New Components:**
1. **Context Document Manager** - Upload domain standards, view RAG extraction
2. **Response Structure Builder** - Visual JSON builder for output format
3. **RAG Pipeline** - Extract domain knowledge from context docs
4. **LLM Meta-Prompter** - Generate domain-aware prompts automatically
5. **Variation Generator** - Create 5-7 prompt variations per iteration
6. **Recommendation Engine** - Analyze results and suggest improvements

**New Database Tables:**
- `eval_opt_context_docs` - Domain documents with RAG metadata
- `eval_opt_response_structures` - BA-defined JSON output formats

**Updated Tables:**
- `eval_opt_runs` - Add context_doc_ids, response_structure_id, generated_prompts

### Design Document

**Location:** `docs/specifications/spec_eval-optimizer-phase4-redesign.md`

**Sections:**
- Problem statement & vision
- Complete architecture overview
- Database schema changes
- Component specifications (6 components with detailed specs)
- Backend architecture (RAG, meta-prompting, pseudocode)
- API specifications
- Implementation phases (4 sub-phases, 3 weeks)
- Success criteria
- Open questions (vector DB, embedding model, LLM choice)

### Implementation Timeline

**Phase 4A:** Context Document Management (Week 1)
**Phase 4B:** Response Structure Builder (Week 1-2)
**Phase 4C:** Automated Optimization (Week 2-3)
**Phase 4D:** Testing & Refinement (Week 3)

**Total:** 3 weeks (vs original 1 week estimate)

### Original Phase 4 Code Status

**Created files (NOW DEPRECATED):**
- `app/projects/[id]/runs/page.tsx` âš ï¸ Needs update (remove manual config)
- `app/projects/[id]/runs/new/page.tsx` âš ï¸ Needs complete redesign
- `components/PromptConfigForm.tsx` âŒ DELETE (manual prompt editing)
- `backend/OPTIMIZATION-ORCHESTRATOR.md` âš ï¸ Update to include RAG + meta-prompting

These files were built on the wrong assumption (manual prompt configuration) and need to be replaced/updated per the redesign.

---

## Next Steps (Phase 4 Redesign)

**Phase 4A: Context Document Management**
- [ ] Create eval_opt_context_docs table
- [ ] Build context document upload UI
- [ ] Implement RAG extraction pipeline
- [ ] Display extracted concepts

**Phase 4B: Response Structure Builder**
- [ ] Create eval_opt_response_structures table  
- [ ] Build visual JSON builder UI
- [ ] Preview pane for response format

**Phase 4C: Automated Optimization**
- [ ] Implement LLM meta-prompter
- [ ] Build variation generator
- [ ] Update orchestrator for RAG + meta-prompting
- [ ] Simplify optimization config UI (remove manual prompt fields)
- [ ] Build recommendation engine

**Phase 4D: Testing**
- [ ] End-to-end testing with real domain docs
- [ ] Validate RAG extraction quality
- [ ] Validate prompt generation quality

---

### February 5, 2026 Afternoon (4:11-4:28 PM) - Workspace-Centric Schema Refactoring

**Session Duration:** 17 minutes  
**Branch:** `feature/eval-optimization-s1` (will transition to s2)  
**Objective:** Refactor database schemas from project-based to workspace-based design

**Critical Architectural Change:**

Through user feedback, we discovered that the "optimization project" abstraction was over-engineered. The workspace itself should be the optimization container, not a separate project entity.

**Decision:** Remove `eval_optimization_projects` and use workspace as the container

**Rationale:**
- Workspace already provides the container concept
- Workspace members already provide access control
- No need for duplicate project/member tables
- Simpler, follows existing CORA patterns
- Context docs live in workspace KB (using existing module-kb)

**Schema Refactoring Completed:**

1. **Tables Removed:**
   - `eval_opt_projects` â†’ Use workspace instead
   - `eval_opt_proj_members` â†’ Use workspace_members
   - `eval_opt_test_orgs` â†’ Not needed

2. **Tables Refactored (proj_id â†’ workspace_id):**
   - `eval_opt_doc_groups` - Changed to workspace_id
   - `eval_opt_runs` - Changed to workspace_id, added Phase 4 fields (context_doc_ids, response_structure_id, generated_prompts)
   - `eval_opt_response_structures` - Replaced prompt_versions table, tied to workspace_id

3. **Tables Unchanged:**
   - `eval_opt_doc_group_members` - References doc_groups (indirect workspace ref)
   - `eval_opt_truth_keys` - References doc_groups (indirect workspace ref)
   - `eval_opt_run_results` - References runs (indirect workspace ref)

4. **RLS Policies Updated:**
   - All policies now check `workspace_id IN (SELECT workspace_id FROM workspace_members WHERE user_id = auth.uid())`
   - Replaced project membership checks with workspace membership checks

**New Schema Files (5 total):**
- `001-eval-opt-doc-groups.sql` - Document groups + members
- `002-eval-opt-truth-keys.sql` - Truth keys for training data
- `003-eval-opt-runs.sql` - Optimization runs + results
- `004-eval-opt-prompt-versions.sql` - Response structures (not prompt versions)
- `005-eval-opt-rls.sql` - All RLS policies

**Archived Files (3 total in db/archived/):**
- `004-eval-opt-runs.sql` (old version with proj_id)
- `005-eval-opt-prompt-versions.sql` (old version with proj_id)
- `006-eval-opt-rls.sql` (old version with project membership)

**Note:** Files 001-003 from Phase 0 were created earlier today and overwritten without being archived (they never existed in git).

**Key Insights:**
- **Context documents** are just KB documents in the workspace (no separate table needed)
- **RAG functionality** provided by existing module-kb APIs
- **Embeddings** provided by existing module-ai APIs
- **Access control** provided by existing workspace_members table

**Next Steps:**
1. Update plan_eval-optimization-s2.md to reflect workspace-centric design
2. Update Phase 1-3 UI code to use workspaces instead of projects
3. Update API documentation to reference workspaces
4. Proceed with Phase 4 implementation (RAG + meta-prompting)

---

---

### February 5, 2026 Afternoon (4:40-4:46 PM) - Phase 4A Planning Session

**Session Duration:** 6 minutes  
**Branch:** `feature/eval-optimization-s2`  
**Objective:** Assess current state and plan Phase 4A implementation

**Findings:**

1. **Database Schema Status Verified:**
   - âœ… `eval_opt_response_structures` EXISTS in 004-eval-opt-prompt-versions.sql (Phase 4B schema complete)
   - âœ… `eval_opt_runs` has Phase 4 redesign fields (context_doc_ids, response_structure_id, generated_prompts)
   - âŒ `eval_opt_context_docs` DOES NOT EXIST (needs to be created for Phase 4A)

2. **Deprecated Code Identified:**
   - `components/PromptConfigForm.tsx` - Manual prompt editing component (WRONG approach, must be deleted)
   - `app/projects/[id]/runs/new/page.tsx` - Uses manual prompt config (needs complete redesign)
   
3. **UI Refactoring Decision:**
   - Phase 1-3 UI still uses "projects" terminology
   - Database uses workspace_id correctly
   - **Decision:** Defer full UI terminology refactor, keep "projects" as UI abstraction for now
   - Rationale: Keeps session focused on Phase 4A implementation

**Session Plan Created:**
- Part 1: Update documentation (this session)
- Part 2: Delete PromptConfigForm.tsx, redesign runs/new with thoroughness selector
- Part 3: Create 006-eval-opt-context-docs.sql schema + update RLS
- Part 4: Create context document manager UI + update API README

**Next Steps:**
- Update context and plan files âœ…
- Begin Part 2: Code cleanup
- Begin Part 3: Phase 4A schema creation
- Begin Part 4: Phase 4A UI scaffolding

---

### February 5, 2026 Afternoon (5:26-5:46 PM) - Database Naming Compliance Fix (ADR-011)

**Session Duration:** 20 minutes  
**Branch:** `feature/eval-optimization-s2`  
**Objective:** Fix database naming violations (workspace_id â†’ ws_id per ADR-011)

**Critical Issue Discovered:**

All eval_opt schema files were created with `workspace_id` column name, violating ADR-011 database naming standards which require using the abbreviated form `ws_id` for foreign keys referencing the `workspaces` table.

**Work Completed:**

1. **Created Cleanup Migration**
   - âœ… Created `000-cleanup-non-compliant-tables.sql`
   - Drops all eval_opt tables created with workspace_id columns
   - Enables clean redeployment with compliant schemas

2. **Fixed All Schema Files (workspace_id â†’ ws_id)**
   - âœ… 001-eval-opt-doc-groups.sql - Fixed column def, comment, composite index
   - âœ… 002-eval-opt-truth-keys.sql - No workspace_id references (already correct)
   - âœ… 003-eval-opt-runs.sql - Fixed column def, comment, 2 composite indexes
   - âœ… 004-eval-opt-prompt-versions.sql - Fixed column def, comment, indexes
   - âœ… 005-eval-opt-context-docs.sql - Fixed column def, comment, indexes
   - âœ… 006-eval-opt-rls.sql - Fixed all RLS policy WHERE clauses

3. **Successful Redeployment**
   - âœ… User ran cleanup migration (dropped non-compliant tables)
   - âœ… User ran all corrected schemas (001-006)
   - âœ… Verified 7 tables created successfully:
     - eval_opt_context_docs
     - eval_opt_doc_group_members
     - eval_opt_doc_groups
     - eval_opt_response_structures
     - eval_opt_run_results
     - eval_opt_runs
     - eval_opt_truth_keys

**Root Cause:**

Initial sed command only replaced `workspace_id UUID` in table definitions but missed:
- Column comments (`COMMENT ON COLUMN table.workspace_id IS ...`)
- Composite indexes (`ON table(workspace_id, status)`)
- Single-column index references

**Fix Applied:**

Multiple sed commands to replace all occurrences:
- Table column definitions
- Column comments
- Index definitions (single and composite)
- RLS policy conditions

**Verification:**

```sql
-- Confirmed 4 tables with ws_id foreign keys:
SELECT table_name, column_name 
FROM information_schema.columns 
WHERE table_name LIKE 'eval_opt_%' AND column_name = 'ws_id';

-- eval_opt_context_docs.ws_id âœ…
-- eval_opt_doc_groups.ws_id âœ…
-- eval_opt_response_structures.ws_id âœ…
-- eval_opt_runs.ws_id âœ…

-- Confirmed 0 workspace_id columns remain:
SELECT table_name, column_name 
FROM information_schema.columns 
WHERE table_name LIKE 'eval_opt_%' AND column_name = 'workspace_id';
-- (No results) âœ…
```

**ADR-011 Compliance Rule:**

> When the related table uses an abbreviated prefix (as documented in Table Naming Rule 6), the foreign key column MUST use that same abbreviation, NOT the spelled-out form.

| Related Table | Foreign Key Column | NOT This âŒ |
|---------------|-------------------|-------------|
| `workspaces` | `ws_id` | `workspace_id` |

**Lesson Learned:**

Always review database naming standards (ADR-011) BEFORE creating any schemas. This mistake cost deployment time to cleanup and redeploy all tables.

**Next Session:**

- Phase 4A: Context Document Management UI implementation
- Phase 4B-D: Response Structure Builder + RAG Pipeline + Automated Optimization

---

**Document Status:** âœ… Sprint 1 Complete, ğŸš§ Sprint 2 In Progress (Phase 4B-C Complete)  
**Last Updated:** February 5, 2026 7:53 PM

---

### February 5, 2026 Evening (7:00-7:53 PM) - Phase 4B-C Backend + Infrastructure Complete

**Session Duration:** 53 minutes  
**Branch:** `feature/eval-optimization-s2`  
**Objective:** Implement backend Lambda, Terraform infrastructure, and ADR-019c compliant module layer

**Phase 4B Completed - Backend Implementation:**

1. **Lambda Orchestrator (`opt-orchestrator/lambda_function.py`)**
   - âœ… ~850 lines of code
   - Routes: POST/GET/DELETE for optimization runs
   - Async worker for background processing
   - 5-phase optimization pipeline:
     - Phase 1: Domain knowledge extraction (RAG)
     - Phase 2: Prompt generation (meta-prompter)
     - Phase 3: Variation generation
     - Phase 4: Evaluation loop (compare to truth keys)
     - Phase 5: Recommendations

2. **Supporting Modules:**
   - âœ… `rag_pipeline.py` - Extract domain knowledge from context docs
   - âœ… `meta_prompter.py` - Generate domain-aware prompts via LLM
   - âœ… `variation_generator.py` - Create 5-12 prompt variations
   - âœ… `recommendation_engine.py` - Generate actionable insights
   - âœ… `requirements.txt` - Lambda dependencies

3. **Build Script:**
   - âœ… `backend/build.sh` - Package Lambda with dependencies

**Phase 4C Completed - Terraform Infrastructure:**

1. **Infrastructure Files:**
   - âœ… `main.tf` - Lambda function, IAM role, API Gateway routes, Lambda layer
   - âœ… `variables.tf` - Input variables including layer zip path
   - âœ… `outputs.tf` - Function ARN, layer ARN, route IDs
   - âœ… `versions.tf` - Terraform/provider version constraints

2. **API Routes Provisioned:**
   - `POST /api/workspaces/{wsId}/optimization/runs` - Start run
   - `GET /api/workspaces/{wsId}/optimization/runs` - List runs
   - `GET /api/workspaces/{wsId}/optimization/runs/{runId}` - Get run
   - `GET /api/workspaces/{wsId}/optimization/runs/{runId}/results` - Detailed results
   - `DELETE /api/workspaces/{wsId}/optimization/runs/{runId}` - Cancel/delete

**Phase 4C+ Completed - Module Layer (ADR-019c):**

1. **Layer Structure:**
   - âœ… `backend/layers/eval_opt_common/build.sh` - Layer build script
   - âœ… `backend/layers/eval_opt_common/python/eval_opt_common/__init__.py`
   - âœ… `backend/layers/eval_opt_common/python/eval_opt_common/permissions.py`

2. **Permission Functions (ADR-011 abbreviated names):**
   - `can_access_opt_ws()` - Check workspace membership
   - `can_access_opt_run()` - Check run access (owner or ws member)
   - `can_manage_opt_run()` - Check run management (owner or ws owner)
   - `is_opt_run_owner()` - Check run ownership
   - `can_access_opt_doc_group()` - Check document group access
   - `can_access_opt_truth_key()` - Check truth key access
   - `can_edit_opt_truth_key()` - Check truth key edit permission

3. **Lambda Updated to Use Layer:**
   - âœ… Imports permission functions from `eval_opt_common`
   - âœ… Removed duplicate `check_workspace_access()` function
   - âœ… Added run-level permission checks (ADR-019c compliant)

**Key Decisions:**
- Function naming follows ADR-011 abbreviations (ws, opt, doc)
- Lambda layer added to Terraform with `create_before_destroy` lifecycle
- Lambda uses both org-common layer AND eval_opt_common layer

**Files Created This Session (15+ files):**
```
backend/
â”œâ”€â”€ build.sh
â”œâ”€â”€ lambdas/opt-orchestrator/
â”‚   â”œâ”€â”€ lambda_function.py (~850 lines)
â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â”œâ”€â”€ meta_prompter.py
â”‚   â”œâ”€â”€ variation_generator.py
â”‚   â”œâ”€â”€ recommendation_engine.py
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ layers/eval_opt_common/
    â”œâ”€â”€ build.sh
    â””â”€â”€ python/eval_opt_common/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ permissions.py

infrastructure/
â”œâ”€â”€ main.tf (~240 lines)
â”œâ”€â”€ variables.tf
â”œâ”€â”€ outputs.tf
â””â”€â”€ versions.tf
```

**Sprint 2 Progress:** 95% complete (Phase 4B-C done, Phase 4D-5 remaining)

**Next Steps:**
1. Phase 4D: Integration testing (deploy and test end-to-end)
2. Phase 5: Results display & A/B comparison

---

### February 5, 2026 Evening (6:34-6:56 PM) - Remaining UI Pages + API Docs Complete

**Session Duration:** 22 minutes  
**Branch:** `feature/eval-optimization-s2`  
**Objective:** Create remaining UI pages and update API documentation

**Completed:**

1. **Runs List Page (`app/ws/[wsId]/runs/page.tsx`)**
   - List of optimization runs with status badges
   - Run cards showing accuracy, samples, criteria counts
   - Progress indicators for running jobs
   - Thoroughness badge (Fast/Balanced/Thorough)
   - Duration formatting for completed runs

2. **Evaluation Page (`app/ws/[wsId]/evaluate/[groupId]/page.tsx`)**
   - Split-screen layout (document left, criteria forms right)
   - Text selection â†’ citation flow
   - Progress tracking (e.g., "7 of 10 evaluated = 70%")
   - Batch save truth keys
   - Uses existing DocumentViewer and CriteriaEvaluationForm components

3. **Sample Upload Page (`app/ws/[wsId]/samples/upload/page.tsx`)**
   - Drag-and-drop file upload via DocumentUploader component
   - Multi-file support (primary + supporting docs)
   - Document list with remove functionality
   - Two-step process: upload files â†’ name sample group

4. **Response Structure Builder Component (`components/ResponseStructureBuilder.tsx`)**
   - Visual JSON builder for defining AI response format
   - Drag-to-reorder sections
   - Type badges (text, list, object, number, boolean)
   - Required field toggle
   - Live JSON preview pane
   - Default sections: score_justification, compliance_gaps, recommendations
   - Additional templates: evidence_cited, risk_assessment, confidence_score, etc.

5. **Response Structure Page (`app/ws/[wsId]/response-structure/page.tsx`)**
   - Name and description fields
   - Embeds ResponseStructureBuilder component
   - Save/update functionality
   - Info box explaining how it works

6. **API README Updated**
   - Added workspace-centric route documentation
   - New endpoints: /workspaces, /workspaces/{wsId}/samples, /runs, /response-structure
   - Thoroughness parameter for optimization runs (fast/balanced/thorough)
   - Status options endpoint

**Files Created (6):**
- `app/ws/[wsId]/runs/page.tsx` (400+ lines)
- `app/ws/[wsId]/evaluate/[groupId]/page.tsx` (400+ lines)
- `app/ws/[wsId]/samples/upload/page.tsx` (390+ lines)
- `app/ws/[wsId]/response-structure/page.tsx` (350+ lines)
- `components/ResponseStructureBuilder.tsx` (425+ lines)
- Updated `app/api/README.md` with workspace routes

**Sprint 2 Progress:** Phase 4A+ UI complete, backend pending

**Total UI Pages Created This Sprint:**
- `app/ws/page.tsx` - Workspace list
- `app/ws/new/page.tsx` - Create workspace
- `app/ws/[wsId]/page.tsx` - Workspace detail (6 tabs)
- `app/ws/[wsId]/context/page.tsx` - Context documents (module-kb)
- `app/ws/[wsId]/runs/page.tsx` - Runs list
- `app/ws/[wsId]/runs/new/page.tsx` - New run (thoroughness)
- `app/ws/[wsId]/evaluate/[groupId]/page.tsx` - Evaluation UI
- `app/ws/[wsId]/samples/upload/page.tsx` - Sample upload
- `app/ws/[wsId]/response-structure/page.tsx` - JSON builder

**Next Steps:**
1. Phase 4B-C: Backend implementation (RAG pipeline + LLM meta-prompting)
2. Phase 4D: Testing & refinement
3. Phase 5: Results display & A/B comparison

---

### February 5, 2026 Evening (6:07-6:32 PM) - Route Refactoring + Context Tab Implementation

**Session Duration:** 25 minutes  
**Branch:** `feature/eval-optimization-s2`  
**Objective:** Refactor routes from /projects/ to /ws/ and implement Context tab using module-kb components

**Completed:**

1. **Route Architecture Refactored:**
   - Changed all routes from `/projects/[id]/` to `/ws/[wsId]/` to match workspace-centric database design
   - Created `app/ws/page.tsx` - Workspace list page (274 lines)
   - Created `app/ws/[wsId]/page.tsx` - Workspace detail with 6 tabs (988 lines)
   - Created `app/ws/[wsId]/context/page.tsx` - Context documents using module-kb (113 lines)
   - Created `app/ws/[wsId]/runs/new/page.tsx` - Optimization run with thoroughness selector (268 lines)

2. **Context Tab Implementation:**
   - "Context" tab added to workspace detail page (single word per user preference)
   - Context page wraps existing `WorkspaceDataKBTab` component from module-kb
   - Added domain-specific guidance explaining RAG purpose
   - Uses existing hooks: `useWorkspaceKB`, `useKbDocuments`
   - **Zero new RAG infrastructure** - uses module-kb APIs

3. **Phase 4 Redesign UI:**
   - Removed manual prompt configuration concept (PromptConfigForm never created)
   - Added thoroughness selector: Fast (5 variations), Balanced (7), Thorough (12)
   - System automatically generates domain-aware prompts via RAG + LLM meta-prompting

4. **Cleanup:**
   - Deleted old `app/projects/` directory

**Key Decisions:**
- Route structure: `/ws/[wsId]/` (not `/projects/[id]/`)
- Tab label: "Context" (single word)
- Section label: "Context Documents" (with RAG explanation)
- No manual prompt editing - system generates prompts automatically

**Files Created (4):**
- `templates/_project-stack-template/apps/eval-optimizer/app/ws/page.tsx`
- `templates/_project-stack-template/apps/eval-optimizer/app/ws/[wsId]/page.tsx`
- `templates/_project-stack-template/apps/eval-optimizer/app/ws/[wsId]/context/page.tsx`
- `templates/_project-stack-template/apps/eval-optimizer/app/ws/[wsId]/runs/new/page.tsx`

**Files Deleted (1):**
- `templates/_project-stack-template/apps/eval-optimizer/app/projects/` (entire directory)

**Sprint 2 Progress:** Phases 0-3 complete, Phase 4A UI complete, Phase 4A backend pending

**Next Steps:**
1. Create remaining pages: `app/ws/new/`, `app/ws/[wsId]/runs/`, `app/ws/[wsId]/evaluate/`, `app/ws/[wsId]/samples/upload/`
2. Implement backend APIs for optimization runs
3. Update API README with workspace-centric endpoints
